<div align="center">
<p>
 <img width="100px" src="https://raw.githubusercontent.com/NekoSilverFox/NekoSilverfox/403ab045b7d9adeaaf8186c451af7243f5d8f46d/icons/silverfox.svg" align="center" alt="NekoSilverfox" />
 <p align="center"><b><font size=6>Block Storage Tester</font></b></p>
 <p align="center"><b>哈希分块存储测试器</b></p>
</p>


[![License](https://img.shields.io/badge/license-Apache%202.0-brightgreen)](LICENSE)
![Qt](https://img.shields.io/badge/Qt-v6.5+-orange)
![Database](https://img.shields.io/badge/Database-PostgreSQL-blue.svg)



<div align="left">
<!-- 顶部至此截止 -->
<div STYLE="page-break-after: always;"></div>



[toc]

>**引言：**
>
>当代数据存储的趋势是创建分布式存储系统，这些系统具有良好的可扩展性、高可靠性、安全性、性能，并能处理巨大量的输入数据。这些分布式存储系统部署在云基础设施中，后者本身具有为各种数据服务创造和使用的巨大潜力。
>
>数据存储的一个重要方面是降低数据存储成本。对于非结构化数据或以字节序列形式存在于磁盘上的数据，可以使用数据去重方法来优化存储。本文提出了在本地存储上实现数据去重解决方案的原型。数据去重指的是在信息存储介质（硬盘）上仅存储唯一数据块的物理存储。
>
>**任何去重算法都基于计算输入数据流块的哈希函数。基于这个哈希函数，系统决定是否已经存在相同的数据块。如果数据块不存在，则将其写入存储；如果存在，则用指向存储中已存在数据的引用来替换它。**
>
>为了判断系统中是否存在具有特定哈希值的数据块，需要保留一个包含哈希值和对应数据块的存储引用的表。 哈希表通常可能包含两列：“哈希值”和“数据块引用”。但需要注意的是，为了去重和垃圾回收，经常需要存储额外信息，比如：数据块的引用计数。

# 目标与任务

本研究的目标是通过使用数据去重方法实现数据的最优存储，并进行性能测试以评估创建的原型的性能。为达到目标，需要解决以下任务：

- 研究在传统数据库中优化数据存储的方法；
- 选择创建去重系统原型所需的技术栈；
- 开发磁盘上的数据最优存储系统；
- **进行负载测试，并确定数据在本地存储中的读写速度与数据块大小的关系；**
- 确定数据块的最优大小，以实现：
    - **最大的写入速度**
    - **最大的读取速度**
    - 将输入数据流分割成指定大小的块；
    - **依赖于使用的哈希算法的数据恢复错误率。**

**系统工作算法** 处理非结构化数据去重的算法可以按以下步骤进行：

- 计算每个块的哈希值；
- 与存储介质上已存在数据的哈希表进行比对；
- 如果数据的哈希值已存在，则只需为输入数据流保存一个引用到已存在的数据；
- 如果数据不存在，则在磁盘上保存新的数据块，并在表中记录这个块的哈希值和相应的位置。



# 需求

## 系统需求

为了有效解决所定义的任务，本工作将实现一个带有图形用户界面的跨平台测试工具。此工具旨在提供用户友好的交互和性能评测功能，支持哈希计算、块大小调整等操作。以下是系统需求和技术需求的详细说明：

- 数据库自动创建和连接功能，以及其他数据表自动管理功能
- 允许用户指定分块大小，块大小为 $2^n, (1 \leq n \leq 11)$
- 允许用户指定源文件、存储块哈希值的文件和恢复文件
- 允许用户指定分块所需的哈希算法
- 程序根据用户输入的源文件、块大小和哈希算法，自动执行文件分块测试：测试流程包括对每个块进行哈希计算、与数据库中的哈希值进行对比、并根据去重策略进行存储数据块的哈希值或数据库引用计数更新
- 支持数据恢复测试：通过读取存储块哈希值文件，将数据重组为原始文件，以验证数据去重和恢复的准确
- 允许测试结果以表格和动态图表的形式呈现，并可以自动记录为 CSV 格式
- 允许用户执行基于某种哈希算法和块大小的单步测试
- 允许用户执行基于指定哈希算法的基准测试

## 技术需求

为了确保系统的稳定性、性能和可扩展性，本项目采用现代软件设计原则和开发技术。以下是系统的技术需求：

- 确保跨平台性和可扩展性
- 程序支持状态保存和恢复
- 采用“高内聚、低耦合”的设计原则，系统划分为表示层（UI）、业务逻辑层（BLL）和数据访问层（DAL），实现功能模块的独立开发和维护
- 支持多线程处理，将计算密集型任务与 UI 显示分离，提升响应速度
- 通过事务机制确保多线程操作下的数据一致性和完整性



# 实施阶段

## 处理流程

对于本项工作，主要需要解决两项**计算任务**，即为

1. **源文件分块任务**：将源文件按指定大小进行分块，计算每个块的哈希值，并将块的哈希值及相关信息存储到数据库中。同时，将源文件的所有块的哈希值保存为块哈希文件（.bkh）。
2. 文件恢复任务：将存有源文件块哈希值的块哈希文件（.bkh）通过数据库中的记录信息进行恢复

以下是两项任务的流程图。

### 源文件分块

对源文件分块的流程图如下：

![seg_flow.drawio_CN](doc/img/seg_flow.drawio_CN.svg)



### 恢复源文件

恢复源文件的流程图如下：

![recover_flow_CN.drawio](doc/img/recover_flow_CN.drawio.svg)

## 数据存储结构

对于本项工作，主要需要解决两项**存储任务**，即为文件块信息在数据库中的记录和分块哈希值记录的存储。在本工作中，他们的设计如下。

### 块信息在数据库中的存储

根据本项工作，每种块大小和其对应的哈希算法都将存储为单独的数据表。对于数据库中数据表的设计如下。共 5 个字段，包含了对于恢复源文件所需的所有信息：

- 当前块的哈希值
- 当前块的源文件路径
- 当前块的在源文件中的起始位置
- 当前块的大小
- 当前块的重复次数

通过以上信息我们便可以借助移动C/C++的指针，来读取指定的块。

并且由于哈希值是唯一的，我们将哈希值设置为了唯一键（UNIQUE），用于加速存储和读取的速度。



### 块文件

我们需要使用一个单独的文件来存储源文件每个块的哈希值，这个文件成为“块哈希文件”，在我们设计的系统中其将被存储为格式 ".bkh" (Block Hash)。对于每种哈希算法，由于其运算之后的长度是固定的，所以我们将在文件内使用连续存储的方式，并且之后恢复文件的时候通过移动指针的方式来读取每条哈希记录。

![image-20241004182139883](doc/img/image-20241004182139883.png)

## 技术栈

对于本项工作，选用了以下技术栈：

我们选择用 C++作为编程语言，利用其高效的内存管理和出色的性能表现，尤其适合实现需要低延迟、高性能的数据处理系统。尽管C++本身提供了强大的标准库支持，但在本项目中，我们更多地依赖于Qt框架的库函数，以实现关键功能的开发。Qt库提供了便捷的数据结构、线程管理、I/O操作等功能，大大简化了开发流程，提高了开发效率。

Qt作为跨平台应用开发框架，不仅提供了强大的UI设计功能，使得我们可以轻松构建用户友好的图形界面来展示系统状态和测试结果，并且借助其信号与槽机制，我们能够在系统中实现高效的异步通信与线程管理。**信号与槽机制**是Qt框架中的核心设计，它基于**观察者模式**，允许对象间进行低耦合的事件传递，特别是在多线程环境下显得尤为重要。如下图所示，通过这种机制，不同对象可以在彼此不直接依赖的情况下进行消息传递，确保了系统的模块化设计和可维护性。

![image-20241004194124045](doc/img/image-20241004194124045.png)

在数据库层面，使用PostgreSQL作为关系型数据库管理系统。PostgreSQL的高可扩展性和复杂查询支持，使其非常适合处理大规模结构化与非结构化数据。在数据去重过程中，PostgreSQL用作存储哈希值和数据块引用的数据库，确保哈希表的快速检索和更新。此外，PostgreSQL的ACID事务支持确保了在并发写操作时的数据一致性，避免了哈希值冲突和写操作冲突的问题，从而提升了系统的稳定性和可靠性。

以下是所使用的框架和工具的具体版本：

- C++ 17
- Qt 6.7.2
- PostgreSQL 16
- Qt Creator 14.0.1

## GUI 设计

我们借助 Qt Design Studio 对程序的界面进行设计，最终的程序 GUI 设计如下图所示：

![res2](doc/img/res2.png)

其中主要包含 2 个主要区域，信息输入区域和结果展示区域

- 通过 ⓵ DataBase 我们可以配置所需要连接的数据库，并且通过点击按钮的方式连接
- 通过 ⓶ Input Segmentation and Recover infomation 我们可以选择需要进行分割的源文件、哈希块文件、恢复文件的位置、分块大小、哈希算法。并且通过按钮点击执行单步测试
- 当前正在执行分块任务的结果将实时显示在 ⓷ Segmentation ouput infomation 区域
- 当前正在执行恢复任务的结果将实时显示在 ⓸ Recover ouput infomation 区域
- 在右侧，用户可以根据选择的哈希算法来进行基准测试，基准测试的结果将实时的绘制在右侧的绘图区
- 所有测试的结果和日志也将以表格的形式展示在左下方的



## 架构

本工作的架构设计如下图所示

![architecture.drawio](doc/img/architecture.drawio.svg)

其中包含 5 个主要的模块，他们的说明如下：

- GUI 模块（主线程）：用于采集用户输入的数据，将其以信号的方式发送给异步计算模块。通过槽接受异步计算的结果，并将分块/恢复任务的结果动态展示在图表中
- 异步计算模块：这个模块将执行实际的分块/恢复任务计算。并且它将连接数据库和直接调用其他模块，计算的结果通过信号的方式发送给GUI模块
- 哈希模块：这个模块封装了各个哈希算法，可以计算每个块的哈希值。并获取关于每个哈希算法的一些信息
- 数据库模块：这个模块包含数据库驱动，并且对本任务中所需要的数据库操作进行了封装。包括：自动连接/创建/删除数据库、数据表的增删改查等
- 文件模块：这个模块封装了本工作所需要的文件操作。如获取文件信息、文件写入读取等



# 结果

本次工作使用了以下开发和测试环境： 
- 操作系统：MacOS Sonoma 14.6.1
- CPU：Apple M1 Pro
- RAM：16 GB

测试可使用的块大小：4KB、8KB、16KB、32KB、64KB、128KB、256KB、512KB、1024KB、2048KB

测试可使用的哈希算法：MD5、SHA1、SHA256、SHA512

测试所使用的文件为：

- 莎士比亚英文全集（大小：10.02 MB）
- JPEG图像（大小：15.3 MB）



## 性能瓶颈

在软件开发的初期，在对系统进行性能测试后发现，大于80%的时间被数据库读取和存储操作所占用。因此我们对数据表的设计进行了优化，为哈希记录增加了唯一键（UNIQUE）。通过使用“莎士比亚英文全集”进行块大小为4KB、哈希算法为 MD5 时分块性能测试，当哈希记录不设有UNIQUE唯一键时，所使用的时间为49745 秒（13.81 小时），而在为数据表中的哈希值增加UNIQUE唯一键并重新测试后，分块用时为49745 秒（13.81 小时），效率提升了？？%。







```
1. 首先获取用于进行分块的哈希算法和大小等信息
2. 打开需要进行分块保存的源文件（指针位于文件头部）
3. 如果指针指向文件尾部，关闭源文件，流程结束
4. 如果指针不指向文件尾部
    1. 读取当前文件块，指针后移
    2. 计算当前文件块的哈希值
    3. 如果哈希值在数据库
    
    
```























