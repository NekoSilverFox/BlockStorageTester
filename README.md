<div align="center">
<p>
 <img width="100px" src="https://raw.githubusercontent.com/NekoSilverFox/NekoSilverfox/403ab045b7d9adeaaf8186c451af7243f5d8f46d/icons/silverfox.svg" align="center" alt="NekoSilverfox" />
 <p align="center"><b><font size=6>Block Storage Tester</font></b></p>
 <p align="center"><b>哈希分块存储测试器</b></p>
</p>


[![License](https://img.shields.io/badge/license-Apache%202.0-brightgreen)](LICENSE)
![Qt](https://img.shields.io/badge/Qt-v6.5+-orange)
![Database](https://img.shields.io/badge/Database-PostgreSQL-blue.svg)



<div align="left">
<!-- 顶部至此截止 -->
<div STYLE="page-break-after: always;"></div>



[toc]

>**引言：**
>
>当代数据存储的趋势是创建分布式存储系统，这些系统具有良好的可扩展性、高可靠性、安全性、性能，并能处理巨大量的输入数据。这些分布式存储系统部署在云基础设施中，后者本身具有为各种数据服务创造和使用的巨大潜力。
>
>数据存储的一个重要方面是降低数据存储成本。对于非结构化数据或以字节序列形式存在于磁盘上的数据，可以使用数据去重方法来优化存储。本文提出了在本地存储上实现数据去重解决方案的原型。数据去重指的是在信息存储介质（硬盘）上仅存储唯一数据块的物理存储。
>
>**任何去重算法都基于计算输入数据流块的哈希函数。基于这个哈希函数，系统决定是否已经存在相同的数据块。如果数据块不存在，则将其写入存储；如果存在，则用指向存储中已存在数据的引用来替换它。**
>
>为了判断系统中是否存在具有特定哈希值的数据块，需要保留一个包含哈希值和对应数据块的存储引用的表。 哈希表通常可能包含两列：“哈希值”和“数据块引用”。但需要注意的是，为了去重和垃圾回收，经常需要存储额外信息，比如：数据块的引用计数。

# 目标与任务

本研究的目标是通过使用数据去重方法实现数据的最优存储，并进行性能测试以评估创建的原型的性能。为达到目标，需要解决以下任务：

- 研究在传统数据库中优化数据存储的方法；
- 选择创建去重系统原型所需的技术栈；
- 开发磁盘上的数据最优存储系统；
- **进行负载测试，并确定数据在本地存储中的读写速度与数据块大小的关系；**
- 确定数据块的最优大小，以实现：
    - **最大的写入速度**
    - **最大的读取速度**
    - 将输入数据流分割成指定大小的块；
    - **依赖于使用的哈希算法的数据恢复错误率。**

**系统工作算法** 处理非结构化数据去重的算法可以按以下步骤进行：

- 计算每个块的哈希值；
- 与存储介质上已存在数据的哈希表进行比对；
- 如果数据的哈希值已存在，则只需为输入数据流保存一个引用到已存在的数据；
- 如果数据不存在，则在磁盘上保存新的数据块，并在表中记录这个块的哈希值和相应的位置。



# 需求

## 系统需求

为了有效解决所定义的任务，本工作将实现一个带有图形用户界面的跨平台测试工具。此工具旨在提供用户友好的交互和性能评测功能，支持哈希计算、块大小调整等操作。以下是系统需求和技术需求的详细说明：

- 数据库自动创建和连接功能，以及其他数据表自动管理功能
- 允许用户指定分块大小，块大小为 $2^n, (1 \leq n \leq 11)$
- 允许用户指定源文件、存储块哈希值的文件和恢复文件
- 允许用户指定分块所需的哈希算法
- 程序根据用户输入的源文件、块大小和哈希算法，自动执行文件分块测试：测试流程包括对每个块进行哈希计算、与数据库中的哈希值进行对比、并根据去重策略进行存储数据块的哈希值或数据库引用计数更新
- 支持数据恢复测试：通过读取存储块哈希值文件，将数据重组为原始文件，以验证数据去重和恢复的准确
- 允许测试结果以表格和动态图表的形式呈现，并可以自动记录为 CSV 格式
- 允许用户执行基于某种哈希算法和块大小的单步测试
- 允许用户执行基于指定哈希算法的基准测试

## 技术需求

为了确保系统的稳定性、性能和可扩展性，本项目采用现代软件设计原则和开发技术。以下是系统的技术需求：

- 确保跨平台性和可扩展性
- 程序支持状态保存和恢复
- 采用“高内聚、低耦合”的设计原则，系统划分为表示层（UI）、业务逻辑层（BLL）和数据访问层（DAL），实现功能模块的独立开发和维护
- 支持多线程处理，将计算密集型任务与 UI 显示分离，提升响应速度
- 通过事务机制确保多线程操作下的数据一致性和完整性



# 实施阶段

## 技术栈

对于本项工作，选用了以下技术栈：

我们选择用 C++作为编程语言，利用其高效的内存管理和出色的性能表现，尤其适合实现需要低延迟、高性能的数据处理系统。尽管C++本身提供了强大的标准库支持，但在本项目中，我们更多地依赖于Qt框架的库函数，以实现关键功能的开发。Qt库提供了便捷的数据结构、线程管理、I/O操作等功能，大大简化了开发流程，提高了开发效率。

Qt作为跨平台应用开发框架，不仅提供了强大的UI设计功能，使得我们可以轻松构建用户友好的图形界面来展示系统状态和测试结果，并且借助其信号与槽机制，我们能够在系统中实现高效的异步通信与线程管理。**信号与槽机制**是Qt框架中的核心设计，它基于**观察者模式**，允许对象间进行低耦合的事件传递，特别是在多线程环境下显得尤为重要。通过这种机制，不同对象可以在彼此不直接依赖的情况下进行消息传递，确保了系统的模块化设计和可维护性。

在数据库层面，使用PostgreSQL作为关系型数据库管理系统。PostgreSQL的高可扩展性和复杂查询支持，使其非常适合处理大规模结构化与非结构化数据。在数据去重过程中，PostgreSQL用作存储哈希值和数据块引用的数据库，确保哈希表的快速检索和更新。此外，PostgreSQL的ACID事务支持确保了在并发写操作时的数据一致性，避免了哈希值冲突和写操作冲突的问题，从而提升了系统的稳定性和可靠性。

## 处理流程



## 数据库



表格式































